{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Stock market prediction using HMM",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting stock closing price from stock data using the Hidden Markov Model to identify latent states"
      ],
      "metadata": {
        "id": "rQzRnHW2jkcN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hidden Markov Model"
      ],
      "metadata": {
        "id": "YLYMW4ZAjkcQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Hidden Markov Model, or HMM for short, may be thought of as a double stochastic process:\n",
        "1. A hidden or latent Markov stochastic process\n",
        "2. An observable stochastic process that produces sequences of observations\n",
        "\n",
        "Since HMMs are often used to capture long-term sequences and hence time-based phenomena, they may prove to be useful in analysis of financial markets."
      ],
      "metadata": {
        "id": "oKWuzIRyjkcR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Goal"
      ],
      "metadata": {
        "id": "5wJ0D04ijkcT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to take the features of opening price, low price, high price and use these to derive some fractional changes. With these fractional changes, we will observe sequences (observations) from which we will derive latent factors in a Markov process. These latent factors will often vary from company to company, which is why it's often hard to fit one linear model of a certain subset of variables for all companies. Once the latent factors and their transitions and starting probabilities (the hidden sequence) are found, we will try to generate some possible values for each of the features and then check how they score with a sequence of test data. The set of possible values that leads to the highest score is then used to predict the closing price for that day."
      ],
      "metadata": {
        "id": "CK8Rn_awjkcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2021-10-09T14:18:00.53844Z",
          "iopub.execute_input": "2021-10-09T14:18:00.539893Z",
          "iopub.status.idle": "2021-10-09T14:18:00.55387Z",
          "shell.execute_reply.started": "2021-10-09T14:18:00.539792Z",
          "shell.execute_reply": "2021-10-09T14:18:00.552246Z"
        },
        "trusted": true,
        "id": "8JbzwXfrjkcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install YFinance to directly download company stock info instead of uploading and using a CSV"
      ],
      "metadata": {
        "id": "lYG2BPnxjkcY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The YFinance module neatly downloads company stock data in the form of a Pandas DataFrame and saves us the trouble of uploading custom CSVs. The same effect can be observed for custom CSVs although a different subset of column names will then have to be assigned."
      ],
      "metadata": {
        "id": "pDeqaJvyjkcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install yfinance"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-09T14:18:00.556396Z",
          "iopub.execute_input": "2021-10-09T14:18:00.556872Z",
          "iopub.status.idle": "2021-10-09T14:18:13.836817Z",
          "shell.execute_reply.started": "2021-10-09T14:18:00.556824Z",
          "shell.execute_reply": "2021-10-09T14:18:13.835496Z"
        },
        "trusted": true,
        "id": "7KccZqqBjkca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import datetime\n",
        "import time\n",
        "import requests\n",
        "import io"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-09T14:18:13.8402Z",
          "iopub.execute_input": "2021-10-09T14:18:13.840567Z",
          "iopub.status.idle": "2021-10-09T14:18:13.857386Z",
          "shell.execute_reply.started": "2021-10-09T14:18:13.840513Z",
          "shell.execute_reply": "2021-10-09T14:18:13.856166Z"
        },
        "trusted": true,
        "id": "g0Bfxk5Njkcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get ^GSPC data"
      ],
      "metadata": {
        "id": "vOgQJcfZjkcd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The S&P 500 index, or Standard & Poorâ€™s 500, is a very important index that tracks the performance of the stocks of 500 large-cap companies in the U.S. The ticker symbol for the S&P 500 index is ^GSPC."
      ],
      "metadata": {
        "id": "klBUwhHVjkce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to download data from 2000 onwards. If we start from 2010, we get very little data to fit our model on and that may lead to inaccurate transition probabilities in the hidden Markov process."
      ],
      "metadata": {
        "id": "_4VHlaW7jkce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = yf.download(\"^GSPC\", start=\"2000-01-01\", end=\"2021-08-01\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-09T14:18:13.859276Z",
          "iopub.execute_input": "2021-10-09T14:18:13.859829Z",
          "iopub.status.idle": "2021-10-09T14:18:14.738799Z",
          "shell.execute_reply.started": "2021-10-09T14:18:13.859743Z",
          "shell.execute_reply": "2021-10-09T14:18:14.738074Z"
        },
        "trusted": true,
        "id": "r0CofV0-jkce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-09T14:18:14.739841Z",
          "iopub.execute_input": "2021-10-09T14:18:14.740115Z",
          "iopub.status.idle": "2021-10-09T14:18:14.765516Z",
          "shell.execute_reply.started": "2021-10-09T14:18:14.740087Z",
          "shell.execute_reply": "2021-10-09T14:18:14.764535Z"
        },
        "trusted": true,
        "id": "Ej_pdrZ_jkcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-09T14:18:14.767017Z",
          "iopub.execute_input": "2021-10-09T14:18:14.767318Z",
          "iopub.status.idle": "2021-10-09T14:18:14.772733Z",
          "shell.execute_reply.started": "2021-10-09T14:18:14.767286Z",
          "shell.execute_reply": "2021-10-09T14:18:14.772009Z"
        },
        "trusted": true,
        "id": "Oiqw6ZWKjkcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "SoHhw1kMjkch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the GSPC data from 1st January, 2000 to 1st August, 2021, there are 5429 entries."
      ],
      "metadata": {
        "id": "sfhLnHOljkch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train-test split"
      ],
      "metadata": {
        "id": "WvmId8-cjkch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For all data, we are going to do a 80-20 train-test split."
      ],
      "metadata": {
        "id": "SCrudzL_jkch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8*data.shape[0])\n",
        "print(train_size)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-09T14:18:14.774414Z",
          "iopub.execute_input": "2021-10-09T14:18:14.775079Z",
          "iopub.status.idle": "2021-10-09T14:18:14.78651Z",
          "shell.execute_reply.started": "2021-10-09T14:18:14.77504Z",
          "shell.execute_reply": "2021-10-09T14:18:14.785337Z"
        },
        "trusted": true,
        "id": "AH3UKZ4ojkch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = data.iloc[0:train_size]\n",
        "test_data = data.iloc[train_size+1:]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-09T14:18:14.789734Z",
          "iopub.execute_input": "2021-10-09T14:18:14.790083Z",
          "iopub.status.idle": "2021-10-09T14:18:14.798016Z",
          "shell.execute_reply.started": "2021-10-09T14:18:14.79005Z",
          "shell.execute_reply": "2021-10-09T14:18:14.796969Z"
        },
        "trusted": true,
        "id": "Wkgv41O2jkci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting features\n",
        "\n"
      ],
      "metadata": {
        "id": "uAkgqcS5jkci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to be working with 3 features:\n",
        "1. The fractional change in opening and closing prices (fracocp)\n",
        "2. The fractional change in high prices (frachp)\n",
        "3. The fractional change in low prices (fraclp)\n",
        "\n",
        "These will be obtained individually in the train and test datasets."
      ],
      "metadata": {
        "id": "5aFo2iMhjkci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_features(dataframe):\n",
        "    fracocp = (dataframe['Close']-dataframe['Open'])/dataframe['Open']\n",
        "    frachp = (dataframe['High']-dataframe['Open'])/dataframe['Open']\n",
        "    fraclp = (dataframe['Open']-dataframe['Low'])/dataframe['Open']\n",
        "    new_dataframe = pd.DataFrame({'delOpenClose': fracocp,\n",
        "                                 'delHighOpen': frachp,\n",
        "                                 'delLowOpen': fraclp})\n",
        "    new_dataframe.set_index(dataframe.index)\n",
        "\n",
        "    return new_dataframe"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-09T14:18:14.800092Z",
          "iopub.execute_input": "2021-10-09T14:18:14.800387Z",
          "iopub.status.idle": "2021-10-09T14:18:14.80912Z",
          "shell.execute_reply.started": "2021-10-09T14:18:14.800356Z",
          "shell.execute_reply": "2021-10-09T14:18:14.80813Z"
        },
        "trusted": true,
        "id": "b-rDKr5Yjkcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(dataframe):\n",
        "    return np.column_stack((dataframe['delOpenClose'], dataframe['delHighOpen'], dataframe['delLowOpen']))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-09T14:18:14.810699Z",
          "iopub.execute_input": "2021-10-09T14:18:14.811066Z",
          "iopub.status.idle": "2021-10-09T14:18:14.820956Z",
          "shell.execute_reply.started": "2021-10-09T14:18:14.811036Z",
          "shell.execute_reply": "2021-10-09T14:18:14.819682Z"
        },
        "trusted": true,
        "id": "zmfAvCiWjkck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = extract_features(augment_features(train_data))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-09T14:18:14.822323Z",
          "iopub.execute_input": "2021-10-09T14:18:14.822641Z",
          "iopub.status.idle": "2021-10-09T14:18:14.836734Z",
          "shell.execute_reply.started": "2021-10-09T14:18:14.822609Z",
          "shell.execute_reply": "2021-10-09T14:18:14.83533Z"
        },
        "trusted": true,
        "id": "iKr3NjsCjkck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-09T14:18:14.838632Z",
          "iopub.execute_input": "2021-10-09T14:18:14.839337Z",
          "iopub.status.idle": "2021-10-09T14:18:14.847938Z",
          "shell.execute_reply.started": "2021-10-09T14:18:14.839291Z",
          "shell.execute_reply": "2021-10-09T14:18:14.84724Z"
        },
        "trusted": true,
        "id": "hPugIjG2jkcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hidden Markov Models with hmmlearn"
      ],
      "metadata": {
        "id": "2mETpeoXjkcl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "1-Wm_UxBjkcm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are first going to import the GaussianHMM from hmmlearn.hmm and then fit it with 10 hidden components (or states) to our training data. We start off with 10 hidden states, but it may be possible to do a grid search among a possible set of values for the number of hidden states to see which works the best."
      ],
      "metadata": {
        "id": "5FNwZCHGjkcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hmmlearn"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-09T14:18:14.848982Z",
          "iopub.execute_input": "2021-10-09T14:18:14.849415Z",
          "iopub.status.idle": "2021-10-09T14:18:22.126719Z",
          "shell.execute_reply.started": "2021-10-09T14:18:14.849384Z",
          "shell.execute_reply": "2021-10-09T14:18:22.125382Z"
        },
        "trusted": true,
        "id": "SkegInJ-jkcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from hmmlearn.hmm import GaussianHMM"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-09T14:18:22.128496Z",
          "iopub.execute_input": "2021-10-09T14:18:22.128808Z",
          "iopub.status.idle": "2021-10-09T14:18:23.28628Z",
          "shell.execute_reply.started": "2021-10-09T14:18:22.128776Z",
          "shell.execute_reply": "2021-10-09T14:18:23.285008Z"
        },
        "trusted": true,
        "id": "P0yl5vULjkco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GaussianHMM(n_components=10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-09T14:18:23.28798Z",
          "iopub.execute_input": "2021-10-09T14:18:23.288405Z",
          "iopub.status.idle": "2021-10-09T14:18:23.295246Z",
          "shell.execute_reply.started": "2021-10-09T14:18:23.288358Z",
          "shell.execute_reply": "2021-10-09T14:18:23.293845Z"
        },
        "trusted": true,
        "id": "T07BOOkqjkcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_train_data = augment_features(train_data)\n",
        "features_train = extract_features(feature_train_data)\n",
        "model.fit(features_train)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-09T14:18:23.29727Z",
          "iopub.execute_input": "2021-10-09T14:18:23.297845Z",
          "iopub.status.idle": "2021-10-09T14:18:32.580954Z",
          "shell.execute_reply.started": "2021-10-09T14:18:23.297798Z",
          "shell.execute_reply": "2021-10-09T14:18:32.579654Z"
        },
        "trusted": true,
        "id": "SLrJvUkJjkcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating possible sequences"
      ],
      "metadata": {
        "id": "IL9r5GCGjkcq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To generate possible possible permutations of values for the features we take the Cartesian product across a range of values for each feature as seen below. We assume a few things here to reduce model complexity.\n",
        "1. We assume that the distribution of each features is across an evenely spaced interval instead of being fully continuous\n",
        "2. We assume possible values for the start and end of the intervals"
      ],
      "metadata": {
        "id": "BJVHuSdrjkcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "test_augmented = augment_features(test_data)\n",
        "fracocp = test_augmented['delOpenClose']\n",
        "frachp = test_augmented['delHighOpen']\n",
        "fraclp = test_augmented['delLowOpen']\n",
        "\n",
        "sample_space_fracocp = np.linspace(fracocp.min(), fracocp.max(), 50)\n",
        "sample_space_fraclp = np.linspace(fraclp.min(), frachp.max(), 10)\n",
        "sample_space_frachp = np.linspace(frachp.min(), frachp.max(), 10)\n",
        "\n",
        "possible_outcomes = np.array(list(itertools.product(sample_space_fracocp, sample_space_frachp, sample_space_fraclp)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-09T14:18:32.582692Z",
          "iopub.execute_input": "2021-10-09T14:18:32.583112Z",
          "iopub.status.idle": "2021-10-09T14:18:32.606222Z",
          "shell.execute_reply.started": "2021-10-09T14:18:32.583068Z",
          "shell.execute_reply": "2021-10-09T14:18:32.605138Z"
        },
        "trusted": true,
        "id": "cyNbEjzIjkcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking predictions"
      ],
      "metadata": {
        "id": "pNQJhQ47jkcr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the data of the last 50 (latent) days to predict the closing price of the current day, and we repeat those for 300 days (this value does not matter at all)"
      ],
      "metadata": {
        "id": "W9BfPA_djkcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_latent_days = 50\n",
        "num_days_to_predict = 300"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-09T14:18:32.607837Z",
          "iopub.execute_input": "2021-10-09T14:18:32.608421Z",
          "iopub.status.idle": "2021-10-09T14:18:32.620167Z",
          "shell.execute_reply.started": "2021-10-09T14:18:32.608367Z",
          "shell.execute_reply": "2021-10-09T14:18:32.61914Z"
        },
        "trusted": true,
        "id": "LXgEem0Yjkct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each of the days that we are going to predict closing prices for, we are going to take the test data for the previous num_latent_days and try each of the outcomes in possible_outcomes to see which sequence generates the highest score. The outcome that generates the highest score is then used to make the predictions for that day's closing price."
      ],
      "metadata": {
        "id": "y3exn3mJjkcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "predicted_close_prices = []\n",
        "for i in tqdm(range(num_days_to_predict)):\n",
        "    # Calculate start and end indices\n",
        "    previous_data_start_index = max(0, i - num_latent_days)\n",
        "    previous_data_end_index = max(0, i)\n",
        "    # Acquire test data features for these days\n",
        "    previous_data = extract_features(augment_features(test_data.iloc[previous_data_start_index:previous_data_end_index]))\n",
        "\n",
        "    outcome_scores = []\n",
        "    for outcome in possible_outcomes:\n",
        "        # Append each outcome one by one with replacement to see which sequence generates the highest score\n",
        "        total_data = np.row_stack((previous_data, outcome))\n",
        "        outcome_scores.append(model.score(total_data))\n",
        "\n",
        "    # Take the most probable outcome as the one with the highest score\n",
        "    most_probable_outcome = possible_outcomes[np.argmax(outcome_scores)]\n",
        "    predicted_close_prices.append(test_data.iloc[i]['Open'] * (1 + most_probable_outcome[0]))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-09T14:18:32.621723Z",
          "iopub.execute_input": "2021-10-09T14:18:32.622183Z",
          "iopub.status.idle": "2021-10-09T14:37:18.865882Z",
          "shell.execute_reply.started": "2021-10-09T14:18:32.622133Z",
          "shell.execute_reply": "2021-10-09T14:37:18.864539Z"
        },
        "trusted": true,
        "id": "xZDS-_Najkcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the predicted closing prices and the actual closing prices, we see the following"
      ],
      "metadata": {
        "id": "Ld3jsYMkjkcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(30,10), dpi=80)\n",
        "plt.rcParams.update({'font.size': 18})\n",
        "\n",
        "x_axis = np.array(test_data.index[0:num_days_to_predict], dtype='datetime64[ms]')\n",
        "plt.plot(x_axis, test_data.iloc[0:num_days_to_predict]['Close'], 'b+-', label=\"Actual close prices\")\n",
        "plt.plot(x_axis, predicted_close_prices, 'ro-', label=\"Predicted close prices\")\n",
        "plt.legend(prop={'size': 20})\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-09T15:29:56.296201Z",
          "iopub.execute_input": "2021-10-09T15:29:56.296667Z",
          "iopub.status.idle": "2021-10-09T15:29:56.586111Z",
          "shell.execute_reply.started": "2021-10-09T15:29:56.296629Z",
          "shell.execute_reply": "2021-10-09T15:29:56.584777Z"
        },
        "trusted": true,
        "id": "wyQ9ss71jkcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ae = abs(test_data.iloc[0:num_days_to_predict]['Close'] - predicted_close_prices)\n",
        "\n",
        "plt.figure(figsize=(30,10), dpi=80)\n",
        "\n",
        "plt.plot(x_axis, ae, 'go-', label=\"Error\")\n",
        "plt.legend(prop={'size': 20})\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-09T15:30:51.797366Z",
          "iopub.execute_input": "2021-10-09T15:30:51.797801Z",
          "iopub.status.idle": "2021-10-09T15:30:52.068453Z",
          "shell.execute_reply.started": "2021-10-09T15:30:51.797764Z",
          "shell.execute_reply": "2021-10-09T15:30:52.067639Z"
        },
        "trusted": true,
        "id": "1QxieaD2jkcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Max error observed = \" + str(ae.max()))\n",
        "print(\"Min error observed = \" + str(ae.min()))\n",
        "print(\"Mean error observed = \" + str(ae.mean()))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-09T14:37:19.595057Z",
          "iopub.execute_input": "2021-10-09T14:37:19.595347Z",
          "iopub.status.idle": "2021-10-09T14:37:19.605Z",
          "shell.execute_reply.started": "2021-10-09T14:37:19.595318Z",
          "shell.execute_reply": "2021-10-09T14:37:19.603553Z"
        },
        "trusted": true,
        "id": "u4T5d6kSjkcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The graphs above show that our model is fairly accurate in predicting the close prices. There is a maximum absolute error of 104.09, a minimum absolute error of 0.05 and a mean absolute error of 10.6812.76. The first graph also shows that there are not very significant gaps between the predictions plot and the actual plot.\n",
        "\n",
        "We also observe that the highest errors occur when the actual closing prices change very sharply (steep rise or fall).\n",
        "\n",
        "However, we can say that our model is able to predict the general trends in the actual closing price movement fairly well, although there are lags observed from time to time."
      ],
      "metadata": {
        "id": "pEGjYda4jkcw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tweaking some hyperparameters"
      ],
      "metadata": {
        "id": "WN90h62zjkcw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be doing some graphs across a range of values for num_latent_days, n_components, and varying the steps in the interval that the features take"
      ],
      "metadata": {
        "id": "4ZKw8dP6jkcx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_latent_days_values = [10, 20, 30, 40, 50, 60]\n",
        "baseline_num_latent_days = 50\n",
        "n_components_values = [4, 6, 8, 10, 12, 14]\n",
        "baseline_n_componets = 10\n",
        "num_steps_values = [10, 20, 40, 50]\n",
        "baseline_num_steps = 50\n",
        "num_days_to_predict = 100 # We don't need to predict as many days as before"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-09T14:37:19.609293Z",
          "iopub.execute_input": "2021-10-09T14:37:19.609671Z",
          "iopub.status.idle": "2021-10-09T14:37:19.615847Z",
          "shell.execute_reply.started": "2021-10-09T14:37:19.609637Z",
          "shell.execute_reply": "2021-10-09T14:37:19.615032Z"
        },
        "trusted": true,
        "id": "_zH1XTksjkcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparing across different values for num_components"
      ],
      "metadata": {
        "id": "mDv_5sW7jkcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mae_num_components = []\n",
        "for num_component in n_components_values:\n",
        "    model = GaussianHMM(n_components=num_component)\n",
        "    model.fit(features_train)\n",
        "    predicted_close_prices = []\n",
        "    for i in tqdm(range(num_days_to_predict)):\n",
        "        # Calculate start and end indices\n",
        "        previous_data_start_index = max(0, i - baseline_num_latent_days)\n",
        "        previous_data_end_index = max(0, i)\n",
        "        # Acquire test data features for these days\n",
        "        previous_data = extract_features(augment_features(test_data.iloc[previous_data_start_index:previous_data_end_index]))\n",
        "\n",
        "        outcome_scores = []\n",
        "        for outcome in possible_outcomes:\n",
        "            # Append each outcome one by one with replacement to see which sequence generates the highest score\n",
        "            total_data = np.row_stack((previous_data, outcome))\n",
        "            outcome_scores.append(model.score(total_data))\n",
        "\n",
        "        # Take the most probable outcome as the one with the highest score\n",
        "        most_probable_outcome = possible_outcomes[np.argmax(outcome_scores)]\n",
        "        predicted_close_prices.append(test_data.iloc[i]['Open'] * (1 + most_probable_outcome[0]))\n",
        "    mae_num_components.append((abs(test_data.iloc[0:num_days_to_predict]['Close'] - predicted_close_prices)).mean())\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-09T14:37:19.617086Z",
          "iopub.execute_input": "2021-10-09T14:37:19.617432Z",
          "iopub.status.idle": "2021-10-09T15:10:44.544319Z",
          "shell.execute_reply.started": "2021-10-09T14:37:19.617401Z",
          "shell.execute_reply": "2021-10-09T15:10:44.543321Z"
        },
        "trusted": true,
        "id": "JKBT_4G-jkcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(30,10), dpi=80)\n",
        "\n",
        "plt.plot(n_components_values, mae_num_components, 'go-', label=\"Error\")\n",
        "plt.xlabel(\"Number of hidden states\")\n",
        "plt.ylabel(\"MAE\")\n",
        "plt.legend(prop={'size': 20})\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-09T15:35:06.766501Z",
          "iopub.execute_input": "2021-10-09T15:35:06.766967Z",
          "iopub.status.idle": "2021-10-09T15:35:07.018722Z",
          "shell.execute_reply.started": "2021-10-09T15:35:06.766932Z",
          "shell.execute_reply": "2021-10-09T15:35:07.017628Z"
        },
        "trusted": true,
        "id": "Q3EkbpPpjkcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we notice that we are able to improve our prediction (as indicated by the lower MAE) going from 4 hidden states to 10, but beyond that there is no significant improvement in the prediction. This leads us to believe that the observations (combination of 3 features) are controlled by 10 hidden states and the emissions of these hidden states.\n",
        "\n",
        "There is also a tradeoff between time to make a prediction and the number of hidden states or components in the model, and so it would make the most sense, to stick to just 10 components (our baseline with which we achieved the overall results)."
      ],
      "metadata": {
        "id": "PO1Y6Xkejkcz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparing across different number of intervals for the feature variables"
      ],
      "metadata": {
        "id": "93Tup4Xijkcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mae_num_steps = []\n",
        "model = GaussianHMM(n_components=baseline_n_componets)\n",
        "model.fit(features_train)\n",
        "for num_step in num_steps_values:\n",
        "    sample_space_fracocp = np.linspace(fracocp.min(), fracocp.max(), num_step)\n",
        "    sample_space_fraclp = np.linspace(fraclp.min(), frachp.max(), int(num_step/5))\n",
        "    sample_space_frachp = np.linspace(frachp.min(), frachp.max(), int(num_step/5))\n",
        "    possible_outcomes = np.array(list(itertools.product(sample_space_fracocp, sample_space_frachp, sample_space_fraclp)))\n",
        "    predicted_close_prices = []\n",
        "    for i in tqdm(range(num_days_to_predict)):\n",
        "        # Calculate start and end indices\n",
        "        previous_data_start_index = max(0, i - baseline_num_latent_days)\n",
        "        previous_data_end_index = max(0, i)\n",
        "        # Acquire test data features for these days\n",
        "        previous_data = extract_features(augment_features(test_data.iloc[previous_data_start_index:previous_data_end_index]))\n",
        "\n",
        "        outcome_scores = []\n",
        "        for outcome in possible_outcomes:\n",
        "            # Append each outcome one by one with replacement to see which sequence generates the highest score\n",
        "            total_data = np.row_stack((previous_data, outcome))\n",
        "            outcome_scores.append(model.score(total_data))\n",
        "\n",
        "        # Take the most probable outcome as the one with the highest score\n",
        "        most_probable_outcome = possible_outcomes[np.argmax(outcome_scores)]\n",
        "        predicted_close_prices.append(test_data.iloc[i]['Open'] * (1 + most_probable_outcome[0]))\n",
        "    mae_num_steps.append((abs(test_data.iloc[0:num_days_to_predict]['Close'] - predicted_close_prices)).mean())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-09T15:10:44.798059Z",
          "iopub.execute_input": "2021-10-09T15:10:44.798518Z",
          "iopub.status.idle": "2021-10-09T15:19:54.791094Z",
          "shell.execute_reply.started": "2021-10-09T15:10:44.798471Z",
          "shell.execute_reply": "2021-10-09T15:19:54.789558Z"
        },
        "trusted": true,
        "id": "dvDUCG9Njkcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(30,10), dpi=80)\n",
        "\n",
        "plt.plot(num_steps_values, mae_num_steps, 'go-', label=\"Error\")\n",
        "plt.xlabel(\"Number of intervals for features\")\n",
        "plt.ylabel(\"MAE\")\n",
        "plt.legend(prop={'size': 20})\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-09T15:35:41.16092Z",
          "iopub.execute_input": "2021-10-09T15:35:41.161339Z",
          "iopub.status.idle": "2021-10-09T15:35:41.425314Z",
          "shell.execute_reply.started": "2021-10-09T15:35:41.161303Z",
          "shell.execute_reply": "2021-10-09T15:35:41.42452Z"
        },
        "trusted": true,
        "id": "czqhw5grjkc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we tried to vary the number of steps in the interval range for each of the features. Intuitively, the finer the interval (a higher number of steps), the closer the distribution gets to becoming continuous and the more accurate a candidate observation may possibly be. However in making the distribution close to continuous, we have to compute the score (or the likelihood of a candidate observation given previous observations) of a much larger number of possible candidate observations and that would require a large amount of computational resources.\n",
        "\n",
        "It is seen above that with a higher number of intervals, the mean absolute error decreases."
      ],
      "metadata": {
        "id": "G9bFmDB9jkc0"
      }
    }
  ]
}